import torch
from transformers import AutoModelForTokenClassification, AutoTokenizer

print("Chargement du modÃ¨le entraÃ®nÃ©...")
model = AutoModelForTokenClassification.from_pretrained('./model_ner_cities')
tokenizer = AutoTokenizer.from_pretrained('./model_ner_cities')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
model.eval()

print(f"ModÃ¨le chargÃ© sur {device}")
print("=" * 60)

# Mapping des labels
id2label = {
    0: 'O',
    1: 'B-DEP',
    2: 'I-DEP',
    3: 'B-ARR',
    4: 'I-ARR'
}


def extraire_villes(tokens, labels):
    """
    Extrait les villes de dÃ©part et d'arrivÃ©e depuis les tokens et labels
    """
    ville_depart = []
    ville_arrivee = []

    for token, label in zip(tokens, labels):
        # Ignorer les tokens spÃ©ciaux
        if token in ['<s>', '</s>', '<pad>']:
            continue

        # Nettoyer le token (enlever le _ de dÃ©but qui reprÃ©sente l'espace)
        token_clean = token.replace('â–', ' ').strip()

        if label in ['B-DEP', 'I-DEP']:
            ville_depart.append(token_clean)
        elif label in ['B-ARR', 'I-ARR']:
            ville_arrivee.append(token_clean)

    # Joindre les tokens pour former les noms complets
    depart = ''.join(ville_depart).strip()
    arrivee = ''.join(ville_arrivee).strip()

    return depart, arrivee


def predire(phrase):
    """
    PrÃ©dit les villes de dÃ©part et d'arrivÃ©e dans une phrase
    """
    # Tokeniser
    inputs = tokenizer(phrase, return_tensors='pt').to(device)

    # PrÃ©dire
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.argmax(outputs.logits, dim=-1)[0]

    # RÃ©cupÃ©rer tokens et labels
    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
    labels_pred = [id2label[p.item()] for p in predictions]

    # Afficher les dÃ©tails
    print("\nğŸ“‹ Analyse dÃ©taillÃ©e :")
    print("-" * 60)
    for token, label in zip(tokens, labels_pred):
        if token not in ['<s>', '</s>', '<pad>']:
            token_display = token.replace('â–', '_')  # Afficher _ pour les espaces
            color = ""
            if label.endswith('DEP'):
                color = "ğŸ”µ"
            elif label.endswith('ARR'):
                color = "ğŸ”´"
            print(f"{color} {token_display:20s} -> {label}")

    # Extraire les villes
    depart, arrivee = extraire_villes(tokens, labels_pred)

    print("\n" + "=" * 60)
    print("ğŸ¯ RÃ‰SULTAT :")
    print(f"   ğŸ”µ Ville de DÃ‰PART  : {depart if depart else 'âŒ Non dÃ©tectÃ©e'}")
    print(f"   ğŸ”´ Ville d'ARRIVÃ‰E  : {arrivee if arrivee else 'âŒ Non dÃ©tectÃ©e'}")
    print("=" * 60)


# ===== BOUCLE INTERACTIVE =====
print("\nğŸš€ Script de test interactif du modÃ¨le NER")
print("Tapez 'quit' ou 'exit' pour quitter\n")

while True:
    print("\n" + "=" * 60)
    phrase = input("ğŸ’¬ Entrez une phrase : ").strip()

    if phrase.lower() in ['quit', 'exit', 'q']:
        print("\nğŸ‘‹ Au revoir !")
        break

    if not phrase:
        print("âš ï¸  Phrase vide, rÃ©essayez.")
        continue

    try:
        predire(phrase)
    except Exception as e:
        print(f"\nâŒ Erreur : {e}")
        print("RÃ©essayez avec une autre phrase.")